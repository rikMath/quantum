{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xLOXFOT5Q40E"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "iiQkM5ZgQ8r2"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j6331ZSsQGY3"
      },
      "source": [
        "# MNIST classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i9Jcnb8bQQyd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/quantum/tutorials/mnist\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/quantum/blob/master/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/quantum/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "udLObUVeGfTs"
      },
      "source": [
        "This tutorial builds a quantum neural network (QNN) to classify a simplified version of MNIST, similar to the approach used in <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al</a>. The performance of the quantum neural network on this classical data problem is compared with a classical neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X35qHdh5Gzqg"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TorxE5tnkvb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.7.0 in ./.venv/lib/python3.8/site-packages (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.24.4)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (2.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (16.0.6)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (2.0.7)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (4.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (0.41.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (2.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.8/site-packages (from tensorflow==2.7.0) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.18.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./.venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.5)\n",
            "Collecting protobuf>=3.9.2 (from tensorflow==2.7.0)\n",
            "  Obtaining dependency information for protobuf>=3.9.2 from https://files.pythonhosted.org/packages/ae/5b/7ed02a9b8e752c8f7bca8661779c0275b9e3e6a903a3045e6da51f796dda/protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata\n",
            "  Using cached protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (56.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.9)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard~=2.6->tensorflow==2.7.0)\n",
            "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/f4/d2/9f6f3b9c0fd486617816cff42e856afea079d0bad99f0e60dc186c76b881/google_auth-2.25.2-py2.py3-none-any.whl.metadata\n",
            "  Using cached google_auth-2.25.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in ./.venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (6.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow==2.7.0) (2.1.3)\n",
            "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.17.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow==2.7.0) (3.2.2)\n",
            "Using cached protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Using cached google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
            "Installing collected packages: protobuf, google-auth\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.18.0\n",
            "    Uninstalling google-auth-1.18.0:\n",
            "      Successfully uninstalled google-auth-1.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 1.21.0 requires google-auth<2.0dev,>=1.18.0, but you have google-auth 2.25.2 which is incompatible.\n",
            "tensorflow-quantum 0.7.2 requires google-auth==1.18.0, but you have google-auth 2.25.2 which is incompatible.\n",
            "tensorflow-quantum 0.7.2 requires protobuf==3.17.3, but you have protobuf 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-2.25.2 protobuf-4.25.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FxkQA6oblNqI"
      },
      "source": [
        "Install TensorFlow Quantum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "saFHsRDpkvkH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-quantum==0.7.2 in ./.venv/lib/python3.8/site-packages (0.7.2)\n",
            "Requirement already satisfied: cirq-core==0.13.1 in ./.venv/lib/python3.8/site-packages (from tensorflow-quantum==0.7.2) (0.13.1)\n",
            "Requirement already satisfied: cirq-google>=0.13.1 in ./.venv/lib/python3.8/site-packages (from tensorflow-quantum==0.7.2) (0.13.1)\n",
            "Requirement already satisfied: sympy==1.8 in ./.venv/lib/python3.8/site-packages (from tensorflow-quantum==0.7.2) (1.8)\n",
            "Requirement already satisfied: googleapis-common-protos==1.52.0 in ./.venv/lib/python3.8/site-packages (from tensorflow-quantum==0.7.2) (1.52.0)\n",
            "Requirement already satisfied: google-api-core==1.21.0 in ./.venv/lib/python3.8/site-packages (from tensorflow-quantum==0.7.2) (1.21.0)\n",
            "Collecting google-auth==1.18.0 (from tensorflow-quantum==0.7.2)\n",
            "  Using cached google_auth-1.18.0-py2.py3-none-any.whl (90 kB)\n",
            "Collecting protobuf==3.17.3 (from tensorflow-quantum==0.7.2)\n",
            "  Using cached protobuf-3.17.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: duet~=0.2.0 in ./.venv/lib/python3.8/site-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (0.2.8)\n",
            "Requirement already satisfied: matplotlib~=3.0 in ./.venv/lib/python3.8/site-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (3.7.3)\n",
            "Requirement already satisfied: networkx~=2.4 in ./.venv/lib/python3.8/site-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (2.8.8)\n",
            "Requirement already satisfied: numpy~=1.16 in ./.venv/lib/python3.8/site-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (1.24.4)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (2.0.3)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.8/site-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (1.10.1)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in ./.venv/lib/python3.8/site-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (2.4.0)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.8/site-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.8/site-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (4.8.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in ./.venv/lib/python3.8/site-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in ./.venv/lib/python3.8/site-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (56.0.0)\n",
            "Requirement already satisfied: six>=1.10.0 in ./.venv/lib/python3.8/site-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (1.16.0)\n",
            "Requirement already satisfied: pytz in ./.venv/lib/python3.8/site-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (2023.3.post1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./.venv/lib/python3.8/site-packages (from google-auth==1.18.0->tensorflow-quantum==0.7.2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.8/site-packages (from google-auth==1.18.0->tensorflow-quantum==0.7.2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.8/site-packages (from google-auth==1.18.0->tensorflow-quantum==0.7.2) (4.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.8/site-packages (from sympy==1.8->tensorflow-quantum==0.7.2) (1.3.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in ./.venv/lib/python3.8/site-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (1.59.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (10.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (6.1.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth==1.18.0->tensorflow-quantum==0.7.2) (0.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum==0.7.2) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum==0.7.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum==0.7.2) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum==0.7.2) (2023.7.22)\n",
            "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.8/site-packages (from pandas->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (2023.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (3.17.0)\n",
            "Installing collected packages: protobuf, google-auth\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.1\n",
            "    Uninstalling protobuf-4.25.1:\n",
            "      Successfully uninstalled protobuf-4.25.1\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.25.2\n",
            "    Uninstalling google-auth-2.25.2:\n",
            "      Successfully uninstalled google-auth-2.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-auth-oauthlib 1.0.0 requires google-auth>=2.15.0, but you have google-auth 1.18.0 which is incompatible.\n",
            "tensorboard 2.14.0 requires protobuf>=3.19.6, but you have protobuf 3.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-1.18.0 protobuf-3.17.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-quantum==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in ./.venv/lib/python3.8/site-packages (0.13.0)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.8/site-packages (from seaborn) (1.24.4)\n",
            "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.8/site-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in ./.venv/lib/python3.8/site-packages (from seaborn) (3.7.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (6.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.3->seaborn) (3.17.0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4Ql5PW-ACO0J"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'pkg_resources' from '/home/henrique/Documentos/quantum/.venv/lib/python3.8/site-packages/pkg_resources/__init__.py'>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Update package resources to account for version changes.\n",
        "import importlib, pkg_resources\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hdgMMZEBGqyl"
      },
      "source": [
        "Now import TensorFlow and the module dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "enZ300Bflq80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-18 21:11:20.363889: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-12-18 21:11:20.363916: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-12-18 21:11:24.335800: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2023-12-18 21:11:24.335870: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (henrique-MS-7C37): /proc/driver/nvidia/version does not exist\n",
            "2023-12-18 21:11:24.336652: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b08Mmbs8lr81"
      },
      "source": [
        "## 1. Load the data\n",
        "\n",
        "In this tutorial you will build a binary classifier to distinguish between the digits 3 and 6, following <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> This section covers the data handling that:\n",
        "\n",
        "- Loads the raw data from Keras.\n",
        "- Filters the dataset to only 3s and 6s.\n",
        "- Downscales the images so they fit can fit in a quantum computer.\n",
        "- Removes any contradictory examples.\n",
        "- Converts the binary images to Cirq circuits.\n",
        "- Converts the Cirq circuits to TensorFlow Quantum circuits. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pDUdGxn-ojgy"
      },
      "source": [
        "### 1.1 Load the raw data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xZyGXlaKojgz"
      },
      "source": [
        "Load the MNIST dataset distributed with Keras. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "d9OSExvCojg0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of original training examples: 60000\n",
            "Number of original test examples: 10000\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
        "\n",
        "print(\"Number of original training examples:\", len(x_train))\n",
        "print(\"Number of original test examples:\", len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fZpbygdGojg3"
      },
      "source": [
        "Filter the dataset to keep just the 3s and 6s,  remove the other classes. At the same time convert the label, `y`, to boolean: `True` for `3` and `False` for 6. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hOw68cCZojg4"
      },
      "outputs": [],
      "source": [
        "def filter_36(x, y):\n",
        "    keep = (y == 3) | (y == 6)\n",
        "    x, y = x[keep], y[keep]\n",
        "    y = y == 3\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "p-XEU8egGL6q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of filtered training examples: 12049\n",
            "Number of filtered test examples: 1968\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = filter_36(x_train, y_train)\n",
        "x_test, y_test = filter_36(x_test, y_test)\n",
        "\n",
        "print(\"Number of filtered training examples:\", len(x_train))\n",
        "print(\"Number of filtered test examples:\", len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3wyiaP0Xojg_"
      },
      "source": [
        "Show the first example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j5STP7MbojhA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f2a500bc4c0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(y_train[0])\n",
        "\n",
        "plt.imshow(x_train[0, :, :, 0])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wNS9sVPQojhC"
      },
      "source": [
        "### 1.2 Downscale the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fmmtplIFGL6t"
      },
      "source": [
        "An image size of 28x28 is much too large for current quantum computers. Resize the image down to 4x4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lbhUdBFWojhE",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Utilizando vários métodos de redução de dimensionalidade\n",
        "\n",
        "x_train_hat_tent = tf.image.resize(x_train, (4,4), method='bilinear', antialias=True).numpy()\n",
        "x_test_hat_tent = tf.image.resize(x_test, (4,4), method='bilinear', antialias=True).numpy()\n",
        "\n",
        "x_train_bilinear = tf.image.resize(x_train, (4,4), method='bilinear').numpy()\n",
        "x_test_bilinear = tf.image.resize(x_test, (4,4), method='bilinear').numpy()\n",
        "\n",
        "x_train_lanczos3 = tf.image.resize(x_train, (4,4), method='lanczos3').numpy()\n",
        "x_test_lanczos3 = tf.image.resize(x_test, (4,4), method='lanczos3').numpy()\n",
        "\n",
        "x_train_lanczos5 = tf.image.resize(x_train, (4,4), method='lanczos5').numpy()\n",
        "x_test_lanczos5 = tf.image.resize(x_test, (4,4), method='lanczos5').numpy()\n",
        "\n",
        "x_train_mitchellcubic = tf.image.resize(x_train, (4,4), method='mitchellcubic').numpy()\n",
        "x_test_mitchellcubic = tf.image.resize(x_test, (4,4), method='mitchellcubic').numpy()\n",
        "\n",
        "x_train_nearest = tf.image.resize(x_train, (4,4), method='nearest').numpy()\n",
        "x_test_nearest = tf.image.resize(x_test, (4,4), method='nearest').numpy()\n",
        "\n",
        "x_train_area = tf.image.resize(x_train, (4,4), method='area').numpy()\n",
        "x_test_area = tf.image.resize(x_test, (4,4), method='area').numpy()\n",
        "\n",
        "x_train_gaussian = tf.image.resize(x_train, (4,4), method='gaussian').numpy()\n",
        "x_test_gaussian = tf.image.resize(x_test, (4,4), method='gaussian').numpy()\n",
        "\n",
        "x_train_bicubic = tf.image.resize(x_train, (4,4), method='bicubic').numpy()\n",
        "x_test_bicubic = tf.image.resize(x_test, (4,4), method='bicubic').numpy()\n",
        "\n",
        "x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
        "x_test_small = tf.image.resize(x_test, (4,4)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pOMd7zIjGL6x"
      },
      "source": [
        "Again, display the first training example—after resize: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YIYOtCRIGL6y",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f2a30501310>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(y_train[0])\n",
        "\n",
        "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gGeF1_qtojhK"
      },
      "source": [
        "### 1.3 Remove contradictory examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ZLkq2yeojhL"
      },
      "source": [
        "From section *3.3 Learning to Distinguish Digits* of <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a>, filter the dataset to remove images that are labeled as belonging to both classes.\n",
        "\n",
        "This is not a standard machine-learning procedure, but is included in the interest of following the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LqOPW0C7ojhL"
      },
      "outputs": [],
      "source": [
        "def remove_contradicting(xs, ys):\n",
        "    return xs, ys\n",
        "    mapping = collections.defaultdict(set)\n",
        "    orig_x = {}\n",
        "    # Determine the set of labels for each unique image:\n",
        "    for x,y in zip(xs,ys):\n",
        "       orig_x[tuple(x.flatten())] = x\n",
        "       mapping[tuple(x.flatten())].add(y)\n",
        "    \n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    for flatten_x in mapping:\n",
        "      x = orig_x[flatten_x]\n",
        "      labels = mapping[flatten_x]\n",
        "      if len(labels) == 1:\n",
        "          new_x.append(x)\n",
        "          new_y.append(next(iter(labels)))\n",
        "      else:\n",
        "          # Throw out images that match more than one label.\n",
        "          pass\n",
        "    \n",
        "    num_uniq_3 = sum(1 for value in mapping.values() if len(value) == 1 and True in value)\n",
        "    num_uniq_6 = sum(1 for value in mapping.values() if len(value) == 1 and False in value)\n",
        "    num_uniq_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
        "\n",
        "    print(\"Number of unique images:\", len(mapping.values()))\n",
        "    print(\"Number of unique 3s: \", num_uniq_3)\n",
        "    print(\"Number of unique 6s: \", num_uniq_6)\n",
        "    print(\"Number of unique contradicting labels (both 3 and 6): \", num_uniq_both)\n",
        "    print()\n",
        "    print(\"Initial number of images: \", len(xs))\n",
        "    print(\"Remaining non-contradicting unique images: \", len(new_x))\n",
        "    \n",
        "    return np.array(new_x), np.array(new_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VMOiJfz_ojhP"
      },
      "source": [
        "The resulting counts do not closely match the reported values, but the exact procedure is not specified.\n",
        "\n",
        "It is also worth noting here that applying filtering contradictory examples at this point does not totally prevent the model from receiving contradictory training examples: the next step binarizes the data which will cause more collisions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zpnsAssWojhP",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique images: 10387\n",
            "Number of unique 3s:  4912\n",
            "Number of unique 6s:  5426\n",
            "Number of unique contradicting labels (both 3 and 6):  49\n",
            "\n",
            "Initial number of images:  12049\n",
            "Remaining non-contradicting unique images:  10338\n"
          ]
        }
      ],
      "source": [
        "x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SlJ5NVaPojhT"
      },
      "source": [
        "### 1.4 Encode the data as quantum circuits\n",
        "\n",
        "To process images using a quantum computer, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed representing each pixel with a qubit, with the state depending on the value of the pixel. The first step is to convert to a binary encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1z8J7OyDojhV"
      },
      "outputs": [],
      "source": [
        "THRESHOLD = 0.5\n",
        "\n",
        "x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
        "x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SlJ5NVaPojhU"
      },
      "source": [
        "If you were to remove contradictory images at this point you would be left with only 193, likely not enough for effective training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1z8J7OyDojhW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique images: 193\n",
            "Number of unique 3s:  80\n",
            "Number of unique 6s:  69\n",
            "Number of unique contradicting labels (both 3 and 6):  44\n",
            "\n",
            "Initial number of images:  10338\n",
            "Remaining non-contradicting unique images:  149\n"
          ]
        }
      ],
      "source": [
        "_ = remove_contradicting(x_train_bin, y_train_nocon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oLyxS9KlojhZ"
      },
      "source": [
        "The qubits at pixel indices with values that exceed a threshold, are rotated through an $X$ gate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aOu_3-3ZGL61"
      },
      "outputs": [],
      "source": [
        "def convert_to_circuit(image):\n",
        "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
        "    values = np.ndarray.flatten(image)\n",
        "    qubits = cirq.GridQubit.rect(4, 4)\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, value in enumerate(values):\n",
        "        if value:\n",
        "            circuit.append(cirq.X(qubits[i]))\n",
        "    return circuit\n",
        "\n",
        "\n",
        "x_train_circ = [convert_to_circuit(x) for x in x_train_bin]\n",
        "x_test_circ = [convert_to_circuit(x) for x in x_test_bin]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zSCXqzOzojhd"
      },
      "source": [
        "Here is the circuit created for the first example (circuit diagrams do not show qubits with zero gates):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "w3POmUEUojhe",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"169.517734375\" height=\"100.0\"><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 2): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"79.517734375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
            ],
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7f2a3048ce50>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SVGCircuit(x_train_circ[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AEQMxCcBojhg"
      },
      "source": [
        "Compare this circuit to the indices where the image value exceeds the threshold:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TBIsiXdtojhh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2, 2],\n",
              "       [3, 1]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bin_img = x_train_bin[0,:,:,0]\n",
        "indices = np.array(np.where(bin_img)).T\n",
        "indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mWZ24w1Oojhk"
      },
      "source": [
        "Convert these `Cirq` circuits to tensors for `tfq`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IZStEMk4ojhk"
      },
      "outputs": [],
      "source": [
        "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
        "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4USiqeOqGL67"
      },
      "source": [
        "## 2. Quantum neural network\n",
        "\n",
        "There is little guidance for a quantum circuit structure that classifies images. Since the classification is based on the expectation of the readout qubit, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose using two qubit gates, with the readout qubit always acted upon. This is similar in some ways to running small a <a href=\"https://arxiv.org/abs/1511.06464\" class=\"external\">Unitary RNN</a> across the pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "knIzawEeojho"
      },
      "source": [
        "### 2.1 Build the model circuit\n",
        "\n",
        "This following example shows this layered approach. Each layer uses *n* instances of the same gate, with each of the data qubits acting on the readout qubit.\n",
        "\n",
        "Start with a simple class that will add a layer of these gates to a circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-hjxxgU5ojho"
      },
      "outputs": [],
      "source": [
        "class CircuitLayerBuilder():\n",
        "    def __init__(self, data_qubits, readout):\n",
        "        self.data_qubits = data_qubits\n",
        "        self.readout = readout\n",
        "    \n",
        "    def add_layer(self, circuit, gate, prefix):\n",
        "        for i, qubit in enumerate(self.data_qubits):\n",
        "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
        "            circuit.append(gate(qubit, self.readout)**symbol)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sjo5hANFojhr"
      },
      "source": [
        "Build an example circuit layer to see how it looks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SzXWOpUGojhs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n",
            "findfont: Font family 'Arial' not found.\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"522.59953125\" height=\"250.0\"><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"129.99353515625\" x2=\"129.99353515625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"230.73810546875004\" x2=\"230.73810546875004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"331.48267578125007\" x2=\"331.48267578125007\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"432.22724609375007\" x2=\"432.22724609375007\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"205.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"89.62125\" y=\"55.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-0)</text><rect x=\"89.62125\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"190.36582031250003\" y=\"105.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-1)</text><rect x=\"190.36582031250003\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"291.11039062500004\" y=\"155.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-2)</text><rect x=\"291.11039062500004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"391.85496093750004\" y=\"205.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-3)</text><rect x=\"391.85496093750004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text></svg>"
            ],
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7f29f15d4ca0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_builder = CircuitLayerBuilder(data_qubits = cirq.GridQubit.rect(4,1),\n",
        "                                   readout=cirq.GridQubit(-1,-1))\n",
        "\n",
        "circuit = cirq.Circuit()\n",
        "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
        "SVGCircuit(circuit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T-QhPE1pojhu"
      },
      "source": [
        "Now build a two-layered model, matching the data-circuit size, and include the preparation and readout operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JiALbpwRGL69"
      },
      "outputs": [],
      "source": [
        "def create_quantum_model():\n",
        "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
        "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
        "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
        "    circuit = cirq.Circuit()\n",
        "    \n",
        "    # Prepare the readout qubit.\n",
        "    circuit.append(cirq.X(readout))\n",
        "    circuit.append(cirq.H(readout))\n",
        "    \n",
        "    builder = CircuitLayerBuilder(\n",
        "        data_qubits = data_qubits,\n",
        "        readout=readout)\n",
        "\n",
        "    # Then add layers (experiment by adding more).\n",
        "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
        "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
        "\n",
        "    # Finally, prepare the readout qubit.\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2QZvVh7vojhx"
      },
      "outputs": [],
      "source": [
        "model_circuit, model_readout = create_quantum_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LY7vbY6yfABE"
      },
      "source": [
        "### 2.2 Wrap the model-circuit in a tfq-keras model\n",
        "\n",
        "Build the Keras model with the quantum components. This model is fed the \"quantum data\", from `x_train_circ`, that encodes the classical data. It uses a *Parametrized Quantum Circuit* layer, `tfq.layers.PQC`, to train the model circuit, on the quantum data.\n",
        "\n",
        "To classify these images, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed taking the expectation of a readout qubit in a parameterized circuit. The expectation returns a value between 1 and -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZYdf_KOxojh0"
      },
      "outputs": [],
      "source": [
        "# Build the Keras model.\n",
        "model = tf.keras.Sequential([\n",
        "    # The input is the data-circuit, encoded as a tf.string\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
        "    tfq.layers.PQC(model_circuit, model_readout),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jz-FbVc9ojh3"
      },
      "source": [
        "Next, describe the training procedure to the model, using the `compile` method.\n",
        "\n",
        "Since the the expected readout is in the range `[-1,1]`, optimizing the hinge loss is a somewhat natural fit. \n",
        "\n",
        "Note: Another valid approach would be to shift the output range to `[0,1]`, and treat it as the probability the model assigns to class `3`. This could be used with a standard a `tf.losses.BinaryCrossentropy` loss.\n",
        "\n",
        "To use the hinge loss here you need to make two small adjustments. First convert the labels, `y_train_nocon`, from boolean to `[-1,1]`, as expected by the hinge loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CgMNkC1Fojh5"
      },
      "outputs": [],
      "source": [
        "y_train_hinge = 2.0*y_train_nocon-1.0\n",
        "y_test_hinge = 2.0*y_test-1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5nwnveDiojh7"
      },
      "source": [
        "Second, use a custiom `hinge_accuracy` metric that correctly handles `[-1, 1]` as the `y_true` labels argument. \n",
        "`tf.losses.BinaryAccuracy(threshold=0.0)` expects `y_true` to be a boolean, and so can't be used with hinge loss)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3XKtZ_TEojh8"
      },
      "outputs": [],
      "source": [
        "def hinge_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true) > 0.0\n",
        "    y_pred = tf.squeeze(y_pred) > 0.0\n",
        "    result = tf.cast(y_true == y_pred, tf.float32)\n",
        "\n",
        "    return tf.reduce_mean(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FlpETlLRojiA"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.Hinge(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[hinge_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jkHq2RstojiC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc (PQC)                   (None, 1)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32\n",
            "Trainable params: 32\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lsuOzDYblA9s"
      },
      "source": [
        "### Train the quantum model\n",
        "\n",
        "Now train the model—this takes about 45 min. If you don't want to wait that long, use a small subset of the data (set `NUM_EXAMPLES=500`, below). This doesn't really affect the model's progress during training (it only has 32 parameters, and doesn't need much data to constrain these). Using fewer examples just ends training earlier (5min), but runs long enough to show that it is making progress in the validation logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "n8vuQpSLlBV2"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "NUM_EXAMPLES = len(x_train_tfcirc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qJnNG-3JojiI"
      },
      "outputs": [],
      "source": [
        "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
        "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QMSdgGC1GL7D"
      },
      "source": [
        "Training this model to convergence should achieve >85% accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ya9qP3KkojiM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324/324 [==============================] - 348s 1s/step - loss: 0.7878 - hinge_accuracy: 0.6615 - val_loss: 0.3821 - val_hinge_accuracy: 0.8090\n",
            "Epoch 2/3\n",
            "324/324 [==============================] - 342s 1s/step - loss: 0.3884 - hinge_accuracy: 0.8177 - val_loss: 0.3405 - val_hinge_accuracy: 0.8609\n",
            "Epoch 3/3\n",
            "324/324 [==============================] - 332s 1s/step - loss: 0.3583 - hinge_accuracy: 0.8716 - val_loss: 0.3314 - val_hinge_accuracy: 0.8740\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.3314 - hinge_accuracy: 0.8740\n"
          ]
        }
      ],
      "source": [
        "qnn_history = model.fit(\n",
        "      x_train_tfcirc_sub, y_train_hinge_sub,\n",
        "      batch_size=32,\n",
        "      epochs=EPOCHS,\n",
        "      verbose=1,\n",
        "      validation_data=(x_test_tfcirc, y_test_hinge))\n",
        "\n",
        "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ER7B7aaojiP"
      },
      "source": [
        "Note: The training accuracy reports the average over the epoch. The validation accuracy is evaluated at the end of each epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8952YvuWGL7J"
      },
      "source": [
        "## 3. Classical neural network\n",
        "\n",
        "While the quantum neural network works for this simplified MNIST problem, a basic classical neural network can easily outperform a QNN on this task. After a single epoch, a classical neural network can achieve >98% accuracy on the holdout set.\n",
        "\n",
        "In the following example, a classical neural network is used for for the 3-6 classification problem using the entire 28x28 image instead of subsampling the image. This easily converges to nearly 100% accuracy of the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pZofEHhLGL7L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1179776   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,198,721\n",
            "Trainable params: 1,198,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_classical_model()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CiAJl7sZojiU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 11s 106ms/step - loss: 0.0410 - accuracy: 0.9826 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=128,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "cnn_results = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X5-5BVJaojiZ"
      },
      "source": [
        "The above model has nearly 1.2M parameters. For a more fair comparison, try a 37-parameter model, on the subsampled images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "70TOM6r-ojiZ",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37\n",
            "Trainable params: 37\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_fair_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
        "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_fair_classical_model()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lA_Fx-8gojid"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "81/81 - 0s - loss: 0.6088 - accuracy: 0.7348 - val_loss: 0.5780 - val_accuracy: 0.7256 - 481ms/epoch - 6ms/step\n",
            "Epoch 2/20\n",
            "81/81 - 0s - loss: 0.5634 - accuracy: 0.8036 - val_loss: 0.5215 - val_accuracy: 0.8186 - 89ms/epoch - 1ms/step\n",
            "Epoch 3/20\n",
            "81/81 - 0s - loss: 0.4972 - accuracy: 0.8140 - val_loss: 0.4565 - val_accuracy: 0.7978 - 92ms/epoch - 1ms/step\n",
            "Epoch 4/20\n",
            "81/81 - 0s - loss: 0.4315 - accuracy: 0.8311 - val_loss: 0.3973 - val_accuracy: 0.8054 - 93ms/epoch - 1ms/step\n",
            "Epoch 5/20\n",
            "81/81 - 0s - loss: 0.3770 - accuracy: 0.8358 - val_loss: 0.3522 - val_accuracy: 0.8089 - 95ms/epoch - 1ms/step\n",
            "Epoch 6/20\n",
            "81/81 - 0s - loss: 0.3363 - accuracy: 0.8421 - val_loss: 0.3189 - val_accuracy: 0.8166 - 93ms/epoch - 1ms/step\n",
            "Epoch 7/20\n",
            "81/81 - 0s - loss: 0.3068 - accuracy: 0.8492 - val_loss: 0.2945 - val_accuracy: 0.8252 - 89ms/epoch - 1ms/step\n",
            "Epoch 8/20\n",
            "81/81 - 0s - loss: 0.2853 - accuracy: 0.8530 - val_loss: 0.2767 - val_accuracy: 0.8262 - 90ms/epoch - 1ms/step\n",
            "Epoch 9/20\n",
            "81/81 - 0s - loss: 0.2697 - accuracy: 0.8541 - val_loss: 0.2639 - val_accuracy: 0.8262 - 107ms/epoch - 1ms/step\n",
            "Epoch 10/20\n",
            "81/81 - 0s - loss: 0.2583 - accuracy: 0.8558 - val_loss: 0.2544 - val_accuracy: 0.8267 - 102ms/epoch - 1ms/step\n",
            "Epoch 11/20\n",
            "81/81 - 0s - loss: 0.2497 - accuracy: 0.8566 - val_loss: 0.2469 - val_accuracy: 0.8272 - 96ms/epoch - 1ms/step\n",
            "Epoch 12/20\n",
            "81/81 - 0s - loss: 0.2430 - accuracy: 0.8583 - val_loss: 0.2407 - val_accuracy: 0.8288 - 97ms/epoch - 1ms/step\n",
            "Epoch 13/20\n",
            "81/81 - 0s - loss: 0.2378 - accuracy: 0.8694 - val_loss: 0.2365 - val_accuracy: 0.8288 - 101ms/epoch - 1ms/step\n",
            "Epoch 14/20\n",
            "81/81 - 0s - loss: 0.2338 - accuracy: 0.8778 - val_loss: 0.2326 - val_accuracy: 0.8674 - 98ms/epoch - 1ms/step\n",
            "Epoch 15/20\n",
            "81/81 - 0s - loss: 0.2307 - accuracy: 0.8760 - val_loss: 0.2296 - val_accuracy: 0.8674 - 97ms/epoch - 1ms/step\n",
            "Epoch 16/20\n",
            "81/81 - 0s - loss: 0.2281 - accuracy: 0.8796 - val_loss: 0.2272 - val_accuracy: 0.8674 - 96ms/epoch - 1ms/step\n",
            "Epoch 17/20\n",
            "81/81 - 0s - loss: 0.2262 - accuracy: 0.8796 - val_loss: 0.2252 - val_accuracy: 0.8674 - 91ms/epoch - 1ms/step\n",
            "Epoch 18/20\n",
            "81/81 - 0s - loss: 0.2246 - accuracy: 0.8797 - val_loss: 0.2238 - val_accuracy: 0.8674 - 90ms/epoch - 1ms/step\n",
            "Epoch 19/20\n",
            "81/81 - 0s - loss: 0.2233 - accuracy: 0.8798 - val_loss: 0.2230 - val_accuracy: 0.8674 - 95ms/epoch - 1ms/step\n",
            "Epoch 20/20\n",
            "81/81 - 0s - loss: 0.2224 - accuracy: 0.8800 - val_loss: 0.2215 - val_accuracy: 0.8674 - 87ms/epoch - 1ms/step\n",
            "62/62 [==============================] - 0s 703us/step - loss: 0.2215 - accuracy: 0.8674\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_bin,\n",
        "          y_train_nocon,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test_bin, y_test))\n",
        "\n",
        "fair_nn_results = model.evaluate(x_test_bin, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RH3mam7EGL7N"
      },
      "source": [
        "## 4. Comparison\n",
        "\n",
        "Higher resolution input and a more powerful model make this problem easy for the CNN. While a classical model of similar power (~32 parameters) trains to a similar accuracy in a fraction of the time. One way or the other, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NOMeN7pMGL7P"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "qnn_accuracy = qnn_results[1]\n",
        "cnn_accuracy = cnn_results[1]\n",
        "fair_nn_accuracy = fair_nn_results[1]\n",
        "\n",
        "ax = sns.barplot(x=[\"Quantum\", \"Classical, full\", \"Classical, fair\"],\n",
        "            y=[qnn_accuracy, cnn_accuracy, fair_nn_accuracy])\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.2f'),\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha = 'center', va = 'center',\n",
        "                xytext = (0, 7),\n",
        "                textcoords = 'offset points')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantum model accuracy: 0.8739919066429138\n",
            "Classical, full data model accuracy: 1.0\n",
            "Classical, fair data model accuracy: 0.8673780560493469\n"
          ]
        }
      ],
      "source": [
        "print(\"Quantum model accuracy:\", qnn_accuracy)\n",
        "print(\"Classical, full data model accuracy:\", cnn_accuracy)\n",
        "print(\"Classical, fair data model accuracy:\", fair_nn_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teste vários modelos clássicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_images = {\n",
        "    \"Bilinear\": x_test_bilinear,\n",
        "    \"Lanczos3\": x_test_lanczos3,\n",
        "    \"Lanczos5\": x_test_lanczos5,\n",
        "    \"Mitchellcubic\": x_test_mitchellcubic,\n",
        "    \"Nearest\": x_test_nearest,\n",
        "    \"Area\": x_test_area,\n",
        "    \"Gaussian\": x_test_gaussian,\n",
        "    \"Bicubic\": x_test_bicubic,\n",
        "    \"Tent\": x_test_hat_tent\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17\n",
            "Trainable params: 17\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "81/81 - 0s - loss: 0.7271 - accuracy: 0.4903 - val_loss: 0.6984 - val_accuracy: 0.5020 - 410ms/epoch - 5ms/step\n",
            "Epoch 2/20\n",
            "81/81 - 0s - loss: 0.6842 - accuracy: 0.5448 - val_loss: 0.6585 - val_accuracy: 0.5051 - 85ms/epoch - 1ms/step\n",
            "Epoch 3/20\n",
            "81/81 - 0s - loss: 0.6455 - accuracy: 0.5501 - val_loss: 0.6225 - val_accuracy: 0.5112 - 86ms/epoch - 1ms/step\n",
            "Epoch 4/20\n",
            "81/81 - 0s - loss: 0.6107 - accuracy: 0.5615 - val_loss: 0.5900 - val_accuracy: 0.5147 - 90ms/epoch - 1ms/step\n",
            "Epoch 5/20\n",
            "81/81 - 0s - loss: 0.5794 - accuracy: 0.5686 - val_loss: 0.5602 - val_accuracy: 0.5285 - 103ms/epoch - 1ms/step\n",
            "Epoch 6/20\n",
            "81/81 - 0s - loss: 0.5510 - accuracy: 0.6031 - val_loss: 0.5336 - val_accuracy: 0.5737 - 98ms/epoch - 1ms/step\n",
            "Epoch 7/20\n",
            "81/81 - 0s - loss: 0.5255 - accuracy: 0.6244 - val_loss: 0.5094 - val_accuracy: 0.5742 - 101ms/epoch - 1ms/step\n",
            "Epoch 8/20\n",
            "81/81 - 0s - loss: 0.5025 - accuracy: 0.6970 - val_loss: 0.4876 - val_accuracy: 0.6997 - 84ms/epoch - 1ms/step\n",
            "Epoch 9/20\n",
            "81/81 - 0s - loss: 0.4817 - accuracy: 0.7369 - val_loss: 0.4676 - val_accuracy: 0.7226 - 90ms/epoch - 1ms/step\n",
            "Epoch 10/20\n",
            "81/81 - 0s - loss: 0.4628 - accuracy: 0.7578 - val_loss: 0.4497 - val_accuracy: 0.7226 - 86ms/epoch - 1ms/step\n",
            "Epoch 11/20\n",
            "81/81 - 0s - loss: 0.4457 - accuracy: 0.7581 - val_loss: 0.4333 - val_accuracy: 0.7231 - 83ms/epoch - 1ms/step\n",
            "Epoch 12/20\n",
            "81/81 - 0s - loss: 0.4301 - accuracy: 0.8247 - val_loss: 0.4184 - val_accuracy: 0.7967 - 96ms/epoch - 1ms/step\n",
            "Epoch 13/20\n",
            "81/81 - 0s - loss: 0.4159 - accuracy: 0.8213 - val_loss: 0.4051 - val_accuracy: 0.7967 - 96ms/epoch - 1ms/step\n",
            "Epoch 14/20\n",
            "81/81 - 0s - loss: 0.4029 - accuracy: 0.8340 - val_loss: 0.3925 - val_accuracy: 0.8364 - 90ms/epoch - 1ms/step\n",
            "Epoch 15/20\n",
            "81/81 - 0s - loss: 0.3910 - accuracy: 0.8328 - val_loss: 0.3811 - val_accuracy: 0.8410 - 95ms/epoch - 1ms/step\n",
            "Epoch 16/20\n",
            "81/81 - 0s - loss: 0.3801 - accuracy: 0.8496 - val_loss: 0.3707 - val_accuracy: 0.8425 - 98ms/epoch - 1ms/step\n",
            "Epoch 17/20\n",
            "81/81 - 0s - loss: 0.3701 - accuracy: 0.8496 - val_loss: 0.3609 - val_accuracy: 0.8425 - 98ms/epoch - 1ms/step\n",
            "Epoch 18/20\n",
            "81/81 - 0s - loss: 0.3608 - accuracy: 0.8536 - val_loss: 0.3522 - val_accuracy: 0.8476 - 94ms/epoch - 1ms/step\n",
            "Epoch 19/20\n",
            "81/81 - 0s - loss: 0.3522 - accuracy: 0.8554 - val_loss: 0.3438 - val_accuracy: 0.8476 - 93ms/epoch - 1ms/step\n",
            "Epoch 20/20\n",
            "81/81 - 0s - loss: 0.3443 - accuracy: 0.8554 - val_loss: 0.3362 - val_accuracy: 0.8481 - 91ms/epoch - 1ms/step\n",
            "62/62 [==============================] - 0s 847us/step - loss: 0.3362 - accuracy: 0.8481\n",
            "Perceptron model accuracy: 0.8480691313743591\n"
          ]
        }
      ],
      "source": [
        "def create_perceptron():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "model = create_perceptron()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train_bin,\n",
        "            y_train_nocon,\n",
        "            batch_size=128,\n",
        "            epochs=20,\n",
        "            verbose=2,\n",
        "            validation_data=(x_test_bin, y_test))\n",
        "\n",
        "perceptron_results = model.evaluate(x_test_bin, y_test)\n",
        "\n",
        "perceptron_accuracy = perceptron_results[1]\n",
        "\n",
        "print(\"Perceptron model accuracy:\", perceptron_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73\n",
            "Trainable params: 73\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "81/81 - 1s - loss: 0.5887 - accuracy: 0.6596 - val_loss: 0.5441 - val_accuracy: 0.6423 - 566ms/epoch - 7ms/step\n",
            "Epoch 2/20\n",
            "81/81 - 0s - loss: 0.5133 - accuracy: 0.7255 - val_loss: 0.4672 - val_accuracy: 0.7729 - 104ms/epoch - 1ms/step\n",
            "Epoch 3/20\n",
            "81/81 - 0s - loss: 0.4392 - accuracy: 0.8042 - val_loss: 0.3985 - val_accuracy: 0.7947 - 103ms/epoch - 1ms/step\n",
            "Epoch 4/20\n",
            "81/81 - 0s - loss: 0.3758 - accuracy: 0.8258 - val_loss: 0.3425 - val_accuracy: 0.8272 - 103ms/epoch - 1ms/step\n",
            "Epoch 5/20\n",
            "81/81 - 0s - loss: 0.3268 - accuracy: 0.8464 - val_loss: 0.3024 - val_accuracy: 0.8298 - 93ms/epoch - 1ms/step\n",
            "Epoch 6/20\n",
            "81/81 - 0s - loss: 0.2926 - accuracy: 0.8501 - val_loss: 0.2755 - val_accuracy: 0.8303 - 99ms/epoch - 1ms/step\n",
            "Epoch 7/20\n",
            "81/81 - 0s - loss: 0.2699 - accuracy: 0.8588 - val_loss: 0.2576 - val_accuracy: 0.8689 - 100ms/epoch - 1ms/step\n",
            "Epoch 8/20\n",
            "81/81 - 0s - loss: 0.2546 - accuracy: 0.8774 - val_loss: 0.2460 - val_accuracy: 0.8704 - 109ms/epoch - 1ms/step\n",
            "Epoch 9/20\n",
            "81/81 - 0s - loss: 0.2444 - accuracy: 0.8736 - val_loss: 0.2377 - val_accuracy: 0.8704 - 118ms/epoch - 1ms/step\n",
            "Epoch 10/20\n",
            "81/81 - 0s - loss: 0.2375 - accuracy: 0.8772 - val_loss: 0.2325 - val_accuracy: 0.8659 - 102ms/epoch - 1ms/step\n",
            "Epoch 11/20\n",
            "81/81 - 0s - loss: 0.2327 - accuracy: 0.8776 - val_loss: 0.2288 - val_accuracy: 0.8664 - 104ms/epoch - 1ms/step\n",
            "Epoch 12/20\n",
            "81/81 - 0s - loss: 0.2291 - accuracy: 0.8775 - val_loss: 0.2259 - val_accuracy: 0.8664 - 97ms/epoch - 1ms/step\n",
            "Epoch 13/20\n",
            "81/81 - 0s - loss: 0.2264 - accuracy: 0.8776 - val_loss: 0.2234 - val_accuracy: 0.8664 - 97ms/epoch - 1ms/step\n",
            "Epoch 14/20\n",
            "81/81 - 0s - loss: 0.2244 - accuracy: 0.8777 - val_loss: 0.2214 - val_accuracy: 0.8674 - 115ms/epoch - 1ms/step\n",
            "Epoch 15/20\n",
            "81/81 - 0s - loss: 0.2228 - accuracy: 0.8787 - val_loss: 0.2203 - val_accuracy: 0.8684 - 121ms/epoch - 1ms/step\n",
            "Epoch 16/20\n",
            "81/81 - 0s - loss: 0.2215 - accuracy: 0.8802 - val_loss: 0.2191 - val_accuracy: 0.8684 - 114ms/epoch - 1ms/step\n",
            "Epoch 17/20\n",
            "81/81 - 0s - loss: 0.2205 - accuracy: 0.8833 - val_loss: 0.2182 - val_accuracy: 0.9151 - 109ms/epoch - 1ms/step\n",
            "Epoch 18/20\n",
            "81/81 - 0s - loss: 0.2196 - accuracy: 0.8893 - val_loss: 0.2172 - val_accuracy: 0.9157 - 91ms/epoch - 1ms/step\n",
            "Epoch 19/20\n",
            "81/81 - 0s - loss: 0.2188 - accuracy: 0.9041 - val_loss: 0.2167 - val_accuracy: 0.9162 - 86ms/epoch - 1ms/step\n",
            "Epoch 20/20\n",
            "81/81 - 0s - loss: 0.2182 - accuracy: 0.9042 - val_loss: 0.2162 - val_accuracy: 0.9162 - 89ms/epoch - 1ms/step\n",
            "62/62 [==============================] - 0s 738us/step - loss: 0.2162 - accuracy: 0.9162\n",
            "Multilayer perceptron model accuracy: 0.9161585569381714\n"
          ]
        }
      ],
      "source": [
        "def create_multilayer_perceptron():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
        "    model.add(tf.keras.layers.Dense(4, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "model = create_multilayer_perceptron()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train_bin,\n",
        "            y_train_nocon,\n",
        "            batch_size=128,\n",
        "            epochs=20,\n",
        "            verbose=2,\n",
        "            validation_data=(x_test_bin, y_test))\n",
        "\n",
        "mlp_results = model.evaluate(x_test_bin, y_test)\n",
        "\n",
        "mlp_accuracy = mlp_results[1]\n",
        "\n",
        "print(\"Multilayer perceptron model accuracy:\", mlp_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 2, 2, 4)           40        \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57\n",
            "Trainable params: 57\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "81/81 - 1s - loss: 0.6330 - accuracy: 0.6252 - val_loss: 0.5831 - val_accuracy: 0.6535 - 544ms/epoch - 7ms/step\n",
            "Epoch 2/20\n",
            "81/81 - 0s - loss: 0.5443 - accuracy: 0.7472 - val_loss: 0.4761 - val_accuracy: 0.7642 - 119ms/epoch - 1ms/step\n",
            "Epoch 3/20\n",
            "81/81 - 0s - loss: 0.4421 - accuracy: 0.8133 - val_loss: 0.3831 - val_accuracy: 0.8211 - 118ms/epoch - 1ms/step\n",
            "Epoch 4/20\n",
            "81/81 - 0s - loss: 0.3704 - accuracy: 0.8292 - val_loss: 0.3279 - val_accuracy: 0.8460 - 110ms/epoch - 1ms/step\n",
            "Epoch 5/20\n",
            "81/81 - 0s - loss: 0.3264 - accuracy: 0.8522 - val_loss: 0.2961 - val_accuracy: 0.8496 - 113ms/epoch - 1ms/step\n",
            "Epoch 6/20\n",
            "81/81 - 0s - loss: 0.3004 - accuracy: 0.8536 - val_loss: 0.2776 - val_accuracy: 0.8506 - 113ms/epoch - 1ms/step\n",
            "Epoch 7/20\n",
            "81/81 - 0s - loss: 0.2841 - accuracy: 0.8550 - val_loss: 0.2667 - val_accuracy: 0.8501 - 108ms/epoch - 1ms/step\n",
            "Epoch 8/20\n",
            "81/81 - 0s - loss: 0.2734 - accuracy: 0.8614 - val_loss: 0.2589 - val_accuracy: 0.8587 - 121ms/epoch - 1ms/step\n",
            "Epoch 9/20\n",
            "81/81 - 0s - loss: 0.2656 - accuracy: 0.8629 - val_loss: 0.2545 - val_accuracy: 0.8587 - 107ms/epoch - 1ms/step\n",
            "Epoch 10/20\n",
            "81/81 - 0s - loss: 0.2599 - accuracy: 0.8654 - val_loss: 0.2504 - val_accuracy: 0.8587 - 129ms/epoch - 2ms/step\n",
            "Epoch 11/20\n",
            "81/81 - 0s - loss: 0.2557 - accuracy: 0.8680 - val_loss: 0.2482 - val_accuracy: 0.8603 - 128ms/epoch - 2ms/step\n",
            "Epoch 12/20\n",
            "81/81 - 0s - loss: 0.2523 - accuracy: 0.8688 - val_loss: 0.2459 - val_accuracy: 0.8613 - 131ms/epoch - 2ms/step\n",
            "Epoch 13/20\n",
            "81/81 - 0s - loss: 0.2495 - accuracy: 0.8781 - val_loss: 0.2443 - val_accuracy: 0.8613 - 129ms/epoch - 2ms/step\n",
            "Epoch 14/20\n",
            "81/81 - 0s - loss: 0.2469 - accuracy: 0.8842 - val_loss: 0.2420 - val_accuracy: 0.8613 - 122ms/epoch - 2ms/step\n",
            "Epoch 15/20\n",
            "81/81 - 0s - loss: 0.2443 - accuracy: 0.8717 - val_loss: 0.2397 - val_accuracy: 0.9080 - 128ms/epoch - 2ms/step\n",
            "Epoch 16/20\n",
            "81/81 - 0s - loss: 0.2422 - accuracy: 0.8936 - val_loss: 0.2384 - val_accuracy: 0.9080 - 139ms/epoch - 2ms/step\n",
            "Epoch 17/20\n",
            "81/81 - 0s - loss: 0.2402 - accuracy: 0.8909 - val_loss: 0.2374 - val_accuracy: 0.9080 - 128ms/epoch - 2ms/step\n",
            "Epoch 18/20\n",
            "81/81 - 0s - loss: 0.2385 - accuracy: 0.8876 - val_loss: 0.2357 - val_accuracy: 0.9090 - 133ms/epoch - 2ms/step\n",
            "Epoch 19/20\n",
            "81/81 - 0s - loss: 0.2370 - accuracy: 0.8948 - val_loss: 0.2346 - val_accuracy: 0.9090 - 130ms/epoch - 2ms/step\n",
            "Epoch 20/20\n",
            "81/81 - 0s - loss: 0.2356 - accuracy: 0.8927 - val_loss: 0.2344 - val_accuracy: 0.8623 - 131ms/epoch - 2ms/step\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.2344 - accuracy: 0.8623\n",
            "Convolutional neural network model accuracy: 0.8622967600822449\n"
          ]
        }
      ],
      "source": [
        "def create_convolutional_neural_network():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(4, [3, 3], activation='relu', input_shape=(4,4,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "model = create_convolutional_neural_network()\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train_bin,\n",
        "            y_train_nocon,\n",
        "            batch_size=128,\n",
        "            epochs=20,\n",
        "            verbose=2,\n",
        "            validation_data=(x_test_bin, y_test))\n",
        "\n",
        "cnn_results = model.evaluate(x_test_bin, y_test)\n",
        "\n",
        "cnn_accuracy = cnn_results[1]\n",
        "\n",
        "print(\"Convolutional neural network model accuracy:\", cnn_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 4)                 144       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 149\n",
            "Trainable params: 149\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "81/81 - 2s - loss: 0.6843 - accuracy: 0.5249 - val_loss: 0.6724 - val_accuracy: 0.4868 - 2s/epoch - 23ms/step\n",
            "Epoch 2/20\n",
            "81/81 - 0s - loss: 0.6619 - accuracy: 0.5249 - val_loss: 0.6424 - val_accuracy: 0.4868 - 225ms/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "81/81 - 0s - loss: 0.6239 - accuracy: 0.5315 - val_loss: 0.5813 - val_accuracy: 0.4990 - 248ms/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "81/81 - 0s - loss: 0.5604 - accuracy: 0.6299 - val_loss: 0.5014 - val_accuracy: 0.6428 - 246ms/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "81/81 - 0s - loss: 0.4991 - accuracy: 0.7084 - val_loss: 0.4382 - val_accuracy: 0.7586 - 248ms/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "81/81 - 0s - loss: 0.4579 - accuracy: 0.7679 - val_loss: 0.4015 - val_accuracy: 0.7998 - 260ms/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "81/81 - 0s - loss: 0.4288 - accuracy: 0.7952 - val_loss: 0.3758 - val_accuracy: 0.8003 - 267ms/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "81/81 - 0s - loss: 0.4047 - accuracy: 0.7984 - val_loss: 0.3562 - val_accuracy: 0.8008 - 271ms/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "81/81 - 0s - loss: 0.3839 - accuracy: 0.8262 - val_loss: 0.3379 - val_accuracy: 0.8653 - 265ms/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "81/81 - 0s - loss: 0.3655 - accuracy: 0.8527 - val_loss: 0.3238 - val_accuracy: 0.8699 - 249ms/epoch - 3ms/step\n",
            "Epoch 11/20\n",
            "81/81 - 0s - loss: 0.3482 - accuracy: 0.8567 - val_loss: 0.3091 - val_accuracy: 0.8770 - 263ms/epoch - 3ms/step\n",
            "Epoch 12/20\n",
            "81/81 - 0s - loss: 0.3318 - accuracy: 0.8552 - val_loss: 0.2962 - val_accuracy: 0.8780 - 258ms/epoch - 3ms/step\n",
            "Epoch 13/20\n",
            "81/81 - 0s - loss: 0.3163 - accuracy: 0.8437 - val_loss: 0.2858 - val_accuracy: 0.8404 - 266ms/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "81/81 - 0s - loss: 0.3027 - accuracy: 0.8538 - val_loss: 0.2777 - val_accuracy: 0.8404 - 237ms/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "81/81 - 0s - loss: 0.2921 - accuracy: 0.8532 - val_loss: 0.2707 - val_accuracy: 0.8420 - 202ms/epoch - 2ms/step\n",
            "Epoch 16/20\n",
            "81/81 - 0s - loss: 0.2836 - accuracy: 0.8574 - val_loss: 0.2639 - val_accuracy: 0.8577 - 209ms/epoch - 3ms/step\n",
            "Epoch 17/20\n",
            "81/81 - 0s - loss: 0.2766 - accuracy: 0.8624 - val_loss: 0.2592 - val_accuracy: 0.8572 - 296ms/epoch - 4ms/step\n",
            "Epoch 18/20\n",
            "81/81 - 0s - loss: 0.2705 - accuracy: 0.8650 - val_loss: 0.2554 - val_accuracy: 0.8572 - 298ms/epoch - 4ms/step\n",
            "Epoch 19/20\n",
            "81/81 - 0s - loss: 0.2650 - accuracy: 0.8654 - val_loss: 0.2522 - val_accuracy: 0.8572 - 277ms/epoch - 3ms/step\n",
            "Epoch 20/20\n",
            "81/81 - 0s - loss: 0.2604 - accuracy: 0.8664 - val_loss: 0.2482 - val_accuracy: 0.8567 - 258ms/epoch - 3ms/step\n",
            "62/62 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.8567\n",
            "Recurrent neural network model accuracy: 0.8567073345184326\n"
          ]
        }
      ],
      "source": [
        "def create_recurrent_neural_network():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.LSTM(4, input_shape=(4,4)))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "model = create_recurrent_neural_network()\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train_bin,\n",
        "            y_train_nocon,\n",
        "            batch_size=128,\n",
        "            epochs=20,\n",
        "            verbose=2,\n",
        "            validation_data=(x_test_bin, y_test))\n",
        "\n",
        "rnn_results = model.evaluate(x_test_bin, y_test)\n",
        "\n",
        "rnn_accuracy = rnn_results[1]\n",
        "\n",
        "print(\"Recurrent neural network model accuracy:\", rnn_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression accuracy is: 90.71\n",
            "Decision Tree accuracy is: 90.92\n",
            "Random Forest accuracy is: 90.92\n",
            "SVM accuracy is: 90.85\n"
          ]
        }
      ],
      "source": [
        "# Teste com o modelo de regressão logística, decision tree, random forest e SVM\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "x_train_flat = np.reshape(x_train_bin, (x_train_bin.shape[0], -1))\n",
        "x_test_flat = np.reshape(x_test_bin, (x_test_bin.shape[0], -1))\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(x_train_flat, y_train_nocon)\n",
        "y_pred = logreg.predict(x_test_flat)\n",
        "acc_logreg = round(logreg.score(x_train_flat, y_train_nocon) * 100, 2)\n",
        "print(\"Logistic Regression accuracy is:\", acc_logreg)\n",
        "\n",
        "# Decision Tree\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(x_train_flat, y_train_nocon)\n",
        "y_pred = decision_tree.predict(x_test_flat)\n",
        "acc_decision_tree = round(decision_tree.score(x_train_flat, y_train_nocon) * 100, 2)\n",
        "print(\"Decision Tree accuracy is:\", acc_decision_tree)\n",
        "\n",
        "# Random Forest\n",
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(x_train_flat, y_train_nocon)\n",
        "y_pred = random_forest.predict(x_test_flat)\n",
        "acc_random_forest = round(random_forest.score(x_train_flat, y_train_nocon) * 100, 2)\n",
        "print(\"Random Forest accuracy is:\", acc_random_forest)\n",
        "\n",
        "# SVM\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC()\n",
        "svm.fit(x_train_flat, y_train_nocon)\n",
        "y_pred = svm.predict(x_test_flat)\n",
        "acc_svm = round(svm.score(x_train_flat, y_train_nocon) * 100, 2)\n",
        "print(\"SVM accuracy is:\", acc_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the accuracy of all the models.\n",
        "ax = sns.barplot(x=[\"Perceptron\", \"Multilayer perceptron\", \"Convolutional neural network\", \"Recurrent neural network\"],\n",
        "            y=[perceptron_accuracy, mlp_accuracy, cnn_accuracy, rnn_accuracy])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "mnist.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
